---
title: "BlogPost"
author: "Felipe Sodré Mendes Barros"
output:
  html_document: default
  pdf_document: default
  word_document: default
---
### Antes de empezar:  
  
Algunas referencias:  

- https://rpubs.com/jboscomendoza/analisis_sentimientos_lexico_afinn  
- https://shiring.github.io/text_analysis/2017/06/28/twitter_post   
- https://uc-r.github.io/hc_clustering   
- https://analyzecore.com/tag/twitter-sentiment-analysis/  
  
```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# creando un tema ggplot
```
  
## Introduccion
  
### CumbreG20  

Fueron analizados publicaciones en el Twitter entre los días 30/11 y 01/12, tanto en inglés como en español, con hashtags relacionada al tema.
  
```{r}
library(rtweet)
library(tidyverse)
library(lubridate)
# text mining library
library(tidytext)
library(wordcloud2)
library(data.table)
library(ggplot2)
#library(cluster)    # clustering algorithms
#library(factoextra) # clustering visualization
#library(tm)

tema_graf <-
  theme_minimal() +
  theme(text = element_text(family = "serif"),
        panel.grid.minor = element_blank(),
        strip.background = element_rect(fill = "#EBEBEB", colour = NA),
        #legend.position = "none",
        legend.box.background = element_rect(fill = "#EBEBEB", colour = NA))
# cargando lexico
afinn <- read.csv("lexico_afinn.en.es.csv", stringsAsFactors = F, fileEncoding = "latin1") %>% 
  tbl_df()

# Identificando stopword
stopword.es <- stopwordslangs %>% filter(lang == "es" & p >= 0.80) %>% select(word)
# inglés
stopword.en <- stopwordslangs %>% filter(lang == "en" & p >= 0.80) %>% select(word)
```
  

```{r}
tweets <- read_twitter_csv("./datos/TodosDatosG20.csv")
tweets <- tweets %>% 
  distinct(status_id, .keep_all = TRUE)
```
   
En el total se recolectó `r nrow(tweets)` tweets a partir de las cuales se buscó responder a las seguientes preguntas:  

- Cuáles fueron los líderes políticos más mencionados?  
- Cuáles fueron las palabras más usadas en general y sus sentimientos asociados?
- Cuáles fueron las palabras más usadas en español y sus sentimientos asociados?  
  
Una vez obtenido los datos, se pudo identificar que los líderes políticos del G20 más influyentes fueron Mauricio Macri, seguido por Donald Trump (EEUU) y Narendra Modi (India). Pero hace falta mencionar que algunos de los políticos más polémicos no tienen perfil en dicha red, como Vladimir Putin (Rusia), Mohammed Bin Salam (Arabia Saudita) y Xi Jinping (China). De hecho, se hizo una búsqueda de dichos líderes a través de "hashtags", lo que nos permitió identificar la influencia de Valdimir Putin, Mohammed Bin Salam y, claro, además del Narendra Modi.
  
```{r}
lideres <- c("abeshinzo",
             "mauriciomacri",
             "AngelaMerkeICDU",
             "realdonaldtrump",
             "theresa_may",
             "rt_erdogan",
             "sanchezcastejon",
             "cyrilramaphosa",
             "leehsienloong",
             "macky_sall",
             "kingsalman",
             "MohammedbinSalman",
             "paulkagame",
             "kremlinrussia_e",
             "_moonjae_in",
             "minpres",
             "epn",
             "andrewholnessjm",
             "GiuseppeConteIT",
             "jokowi",
             "narendramodi",
             "EmmanuelMacron",
             "eucopresident",
             "JunckerEU",
             "xjJinping",
             "sebastianpinera",
             "JustinTrudeau",
             "MichelTemer",
             "ScottMorrisonMP",
             "putin")
lideres <- lideres %>% tolower()
```
  
```{r}
tweets %>% 
  unnest_tokens(input = "mentions_screen_name", output = "Mentions") %>% 
  select(Mentions) %>% 
  filter(!is.na(Mentions), Mentions %in% lideres) %>% 
  count(Mentions, sort = TRUE) %>% 
  top_n(3) %>% 
  ggplot( aes(reorder(Mentions, -n), n)) + 
  geom_col() + 
  labs(x = "Lideres",
         y = "Cantidad de menciones") + 
  tema_graf
#ggsave("./graficos/LideresMencionados.png", dpi = 300)
```
  

```{r}
tweets %>% 
  unnest_tokens(input = "hashtags", output = "Hashtags") %>% 
  select(Hashtags) %>% 
  filter(!is.na(Hashtags), Hashtags %in% lideres) %>% 
  count(Hashtags, sort = TRUE) %>% 
  top_n(3) %>% 
  ggplot( aes(reorder(Hashtags, -n), n)) + 
  geom_col() + 
  labs(x = "Lideres",
         y = "Cantidad de menciones por #") + 
  tema_graf
#ggsave("./graficos/LideresMencionados#.png", dpi = 300)
```
  
```{r}
afinnALL <- afinn %>% gather("Categoria", "Palabra", Palabra, Word) %>% 
  select(Puntuacion, Palabra)
# Separando ES, EN y filtrando dias de cumbre
tw.en <- 
  tweets %>%
  mutate(Dia = day(created_at),
         Mes = month(created_at),
         Hora = hour(created_at),
         text = tolower(text)) %>% 
  filter((Dia == 30 | Dia == 1) & lang == "en") %>%   # filtrando días de la cumbre
    unnest_tokens(input = "text", output = "Word") %>% # separa cada palabra del texto
  inner_join(afinn, ., by = "Word") %>% # join con lexico es
  mutate(Tipo = ifelse(Puntuacion > 0, "Positiva", "Negativa")) %>% 
  filter(! Palabra %in% stopword.en$word )

tw.es <- 
  tweets %>%
  mutate(Dia = day(created_at),
         Mes = month(created_at),
         Hora = hour(created_at),
         text = tolower(text)) %>% 
  filter((Dia == 30 | Dia == 1) & lang == "es") %>%   # filtrando días de la cumbre
  unnest_tokens(input = "text", output = "Palabra") %>% # separa cada palabra del texto
  inner_join(afinnALL, ., by = "Palabra") %>% # join con lexico es
  mutate(Tipo = ifelse(Puntuacion > 0, "Positiva", "Negativa")) %>% filter(! Palabra %in% stopword.es$word )

MergedMentions <- tweets %>% 
  unnest_tokens(input = "mentions_screen_name", output = "Mentions") %>% 
  filter(!is.na(Mentions), Mentions %in% lideres) %>% 
  unnest_tokens(input = "hashtags", output = "Hashtags") %>% 
  gather("origin", "MentionsMerged", Mentions, Hashtags) %>% 
  filter(!is.na(MentionsMerged), MentionsMerged %in% lideres)

all <- MergedMentions %>%
  mutate(Dia = day(created_at),
         Mes = month(created_at),
         Hora = hour(created_at),
         text = tolower(text)) %>% 
  filter(Dia == 30 | Dia == 1) %>%   # filtrando días de la cumbre
  unnest_tokens(input = "text", output = "Palabra") %>%
  inner_join(afinnALL, ., by = "Palabra") %>% # join con lexico
  mutate(Tipo = ifelse(Puntuacion > 0, "Positiva", "Negativa")) %>% 
  filter((! Palabra %in% stopword.en$word) | (! Palabra %in% stopword.es$word) )
```
  
De todos los tweets recolectados en ambos idiomas (izquierda), las dos palabras más usadas estaban en español, siendo "Gracias" la palabra más usadas con 773 tweets, seguido de "Orgullo" con 401. Ahora, si se analiza solamente los tweets originados en dispostivos de idioma español (derecha), tenemos que las tres palabras más frecuentes fueron "Emocionado","Asesinato" y "Emocionante" con poca diferencia de tweets entre cada uno.  
   
```{r}
all %>% 
  group_by(Palabra) %>% 
  count(sort = T) %>% 
  top_n(50) %>% 
  filter(n >= 50) %>% 
  wordcloud2(size = 0.5, maxRotation = 0, shuffle = FALSE)
```
  
```{r}
tw.es %>% 
  group_by(Palabra) %>% 
  count(sort = T) %>% 
  top_n(50) %>% 
  wordcloud2(size = 0.5, maxRotation = 0, shuffle = FALSE)

#tw.en %>% 
#  group_by(Word) %>% 
#  count(sort = T) %>% 
#  wordcloud2(size = 0.5, maxRotation = 0, shuffle = FALSE)
```
  
Sabiendo cuales fueron las palabras más usadas en español, surgió la siguiente pregunta? A qué o quienes hace referencia estas palabras?  
Es por esto que se realizó un análisis temporal de los tweets de cada palabra usada y se discubrió que habia una mayor concentración de tweets con las palabras "emocionado" y "emocionante" entre las 20 y 24 horas del día 30 de Noviembre, por lo tanto concluimos de que dichas palabras están relacionadas con el evento "Argentum" en el teatro Colón.  

```{r}
all %>% 
  filter((Palabra == "emocionado") | (Palabra == "emocionante")) %>% 
  ts_plot("2 hours") +
  labs (x = "Fecha",
         y = "Cantidad de tweets")
#ggsave("./graficos/TimeseriesEmocionado.png", dpi = 300)
```

Ahora para entender lo que se taba comentando en relación a la palabra "asesinato", buscamos identificar los líderes políticos más relacionados a palabras negativas (grafico abajo) y a través del cual se nota Mohammed Bin Salam, como el lider más palabras negativas asociadas.  
  
```{r}
all %>% 
  group_by(MentionsMerged, status_id) %>% 
  filter((!is.na(MentionsMerged)), MentionsMerged %in% lideres) %>%
  summarise(Promedio = mean(Puntuacion)) %>% 
  summarise(PromedioLider = mean(Promedio)) %>% 
  mutate(Tipo = ifelse(PromedioLider >= 0, "Positiva", "Negativa")) %>% 
  filter(Tipo == "Negativa") %>% 
  ggplot( aes(reorder(MentionsMerged, -PromedioLider), PromedioLider, fill = Tipo)) +
  geom_col() +
  coord_flip() +
  labs(x = "Lider",
         y = "") + 
  tema_graf
#ggsave("./graficos/LideresNegativos.png", dpi = 300)
```  

En base a eso, buscamos identificar cuales parabras fueron más usadas en los tweets donde se menciona Mohammed Bin Salam. Por eso se hizo un nuevo gráfico donde se nota, dentre otras palabras, "murderer" (asesino). Eso esta relacionado al asesinato del periodista Jamal Kashagoshi, muerto en la embajada de Arabia Saudita en Tukia, siendo Mohammed Bin Salan sospecho del mandante del crimen ya que Jamal representaba oposición al régimen del monarca.  
```{r}
all %>% 
  filter((MentionsMerged == "kingsalman") | (MentionsMerged == "mohammedbinsalman")) %>%
  filter(Tipo == "Negativa") %>%
  select(Palabra) %>% 
  count(Palabra,sort = TRUE) %>% 
  top_n(100) %>% 
  wordcloud2(size = 0.5, maxRotation = 0, shuffle = FALSE)
```  
En general se udo percibir que, del evento geopolítico G20 los mensajes positivos esuvieron relacionados a elementos sociales, como el espetáculo "Argentum" que ocurrio en el Teatro Colón, mientras que las palabras negativas estaban relacionada a cuestiones políticas internacionales, como el asesinato del periodista Jamal y la crisis en Fracia.  
De esta forma, hacendo uso de técnicas de minería de textos y análsis de sentimientos, se percibe el gran potencial de las redes sociales en nos brindar informaciones y conocimientos a respecto de las tendencia y sentimientos de sus usuários.